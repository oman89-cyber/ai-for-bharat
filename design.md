# OG AI Chatbot - Design Document

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     User Interfaces                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Web UI         â”‚  Voice Call      â”‚  Direct API          â”‚
â”‚  (Browser)       â”‚  (Twilio)        â”‚  (HTTP Client)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚                    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  FastAPI       â”‚
                    â”‚  Backend       â”‚
                    â”‚  (Port 8000)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                  â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚  Local  â”‚        â”‚Hugging  â”‚       â”‚ OpenAI  â”‚
    â”‚ Ollama  â”‚        â”‚  Face   â”‚       â”‚  API    â”‚
    â”‚(11434)  â”‚        â”‚  API    â”‚       â”‚         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Design

### 1. FastAPI Backend (`main.py`)

**Responsibilities:**
- Central AI orchestration
- Provider fallback management
- Request validation
- CORS handling

**Key Functions:**
- `ask_local()` - Query local Ollama instance
- `ask_hf()` - Query Hugging Face API
- `ask_openai()` - Query OpenAI API
- `ask_ai()` - Main endpoint with fallback logic

**Data Flow:**
```
User Question
    â†“
POST /ask
    â†“
Question Model Validation
    â†“
Try Local Ollama
    â”œâ”€ Success â†’ Return with source
    â””â”€ Fail â†’ Try Hugging Face
         â”œâ”€ Success â†’ Return with source
         â””â”€ Fail â†’ Try OpenAI
              â”œâ”€ Success â†’ Return with source
              â””â”€ Fail â†’ Return error
```

### 2. Flask Voice Interface (`SERVER.PY`)

**Responsibilities:**
- Twilio webhook handling
- TwiML response generation
- Voice conversation loop

**Request/Response Cycle:**
```
Twilio Call
    â†“
GET/POST /voice
    â†“
Check for SpeechResult
    â”œâ”€ No speech (first call)
    â”‚  â””â”€ Return: Welcome prompt + Gather
    â”‚
    â””â”€ Has speech
       â”œâ”€ Send to FastAPI /ask
       â”œâ”€ Get AI response
       â””â”€ Return: AI answer + Gather for next input
```

**TwiML Structure:**
- `<Say>` - Text-to-speech output
- `<Gather>` - Speech input collection
- `timeout="6"` - Wait 6 seconds for speech

### 3. Web UI Frontend

**Architecture:**
```
index.html (Structure)
    â†“
style.css (Presentation)
    â†“
script.js (Behavior)
```

**Key Components:**

| Component | Purpose |
|-----------|---------|
| Chat Box | Display message history |
| Input Field | User text entry |
| Send Button | Submit text message |
| Voice Button | Trigger speech recognition |

**State Management:**
- Chat history in DOM
- LocalStorage for persistence
- No backend state (stateless)

**User Interactions:**
```
Text Input:
  User types â†’ Press Enter/Send
    â†“
  Fetch POST /ask
    â†“
  Display typing indicator
    â†“
  Receive response
    â†“
  Display message + Speak

Voice Input:
  Click ğŸ¤ button
    â†“
  Browser speech recognition starts
    â†“
  User speaks
    â†“
  Auto-submit recognized text
    â†“
  Same as text flow
```

## Data Models

### Question (Pydantic)
```python
{
  "text": str  # User question
}
```

### AI Response
```python
{
  "answer": str,      # AI response text
  "source": str       # "local" | "huggingface" | "openai"
}
```

### Error Response
```python
{
  "error": str  # Error message
}
```

## Provider Strategy

### Local Ollama
- **Model:** tinyllama
- **Pros:** Fast, no API costs, privacy
- **Cons:** Limited capability, requires local setup
- **Response Limit:** 120 characters
- **Timeout:** 120 seconds

### Hugging Face
- **Model:** google/flan-t5-base
- **Pros:** Free tier, good quality
- **Cons:** Slower than local, rate limits
- **Max Tokens:** 200

### OpenAI
- **Model:** gpt-4-mini
- **Pros:** Best quality, most capable
- **Cons:** Requires API key, costs money
- **Fallback:** Last resort

## UI/UX Design

### Color Scheme
- **Background:** Dark (`#020617`)
- **Container:** Slate (`#0f172a`)
- **Accent:** Cyan (`#38bdf8`)
- **User Messages:** Cyan
- **Bot Messages:** Teal (`#a7f3d0`)

### Layout
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    OG Chatbot (Header)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                             â”‚
â”‚  Chat Box (360px height)    â”‚
â”‚  - User messages (right)    â”‚
â”‚  - Bot messages (left)      â”‚
â”‚  - Fade-in animation        â”‚
â”‚                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Input Field] [Send] [ğŸ¤]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Responsive Behavior
- Fixed width: 420px
- Centered on screen
- Scrollable chat history
- Touch-friendly buttons

## Error Handling

### Backend
```
Try-Except Pattern:
  â”œâ”€ Network errors â†’ Return empty string
  â”œâ”€ API errors â†’ Return empty string
  â”œâ”€ Timeout â†’ Return empty string
  â””â”€ All fail â†’ Return error object
```

### Frontend
```
Fetch Error Handling:
  â”œâ”€ Network error â†’ Show error message
  â”œâ”€ Invalid response â†’ Show error message
  â””â”€ Success â†’ Display response
```

## Security Considerations

### CORS
- Allow all origins (`*`)
- Suitable for public API
- Consider restricting in production

### Environment Variables
- API keys stored in `.env`
- Never commit `.env` to version control
- Load via `python-dotenv`

### Input Validation
- Pydantic validates request body
- Text field required
- No SQL injection risk (no database)

### Voice Interface
- Twilio handles authentication
- TwiML prevents code injection
- No direct user input execution

## Performance Optimization

### Caching Opportunities
- Cache common questions
- Store provider responses
- LocalStorage for chat history

### Timeout Strategy
- Ollama: 120 seconds
- Hugging Face: Default (varies)
- OpenAI: Default (varies)
- Fallback prevents hanging

### Response Limiting
- Local: 120 char hard limit
- Prevents excessive output
- Faster response times

## Scalability Considerations

### Current Limitations
- Single FastAPI instance
- No database
- No user authentication
- No rate limiting

### Future Improvements
- Load balancing for multiple FastAPI instances
- Database for chat history
- User authentication & authorization
- Rate limiting per user/IP
- Caching layer (Redis)
- Message queue for async processing

## Deployment Architecture

### Development
```
Local Machine:
  â”œâ”€ FastAPI (localhost:8000)
  â”œâ”€ Flask (localhost:5001)
  â”œâ”€ Ollama (localhost:11434)
  â””â”€ Web UI (file://)
```

### Production
```
Cloud Server:
  â”œâ”€ FastAPI (gunicorn/uvicorn)
  â”œâ”€ Flask (gunicorn)
  â”œâ”€ Ollama (optional, or use cloud LLM)
  â”œâ”€ Nginx (reverse proxy)
  â”œâ”€ SSL/TLS (HTTPS)
  â””â”€ Web UI (static hosting)
```

## Integration Points

### External APIs
1. **Ollama** - Local LLM inference
2. **Hugging Face** - Cloud inference
3. **OpenAI** - GPT-4 Mini
4. **Twilio** - Voice interface (optional)
5. **Web Speech API** - Browser voice

### Communication Protocols
- HTTP/REST for APIs
- TwiML for Twilio
- WebSocket (future enhancement)

## Testing Strategy

### Unit Tests
- Provider functions (ask_local, ask_hf, ask_openai)
- Data model validation
- Error handling

### Integration Tests
- Full /ask endpoint flow
- Fallback logic
- Voice endpoint

### E2E Tests
- Web UI chat flow
- Voice input/output
- Chat persistence

## Future Enhancements

1. **User Accounts** - Authentication & chat history
2. **Streaming Responses** - Real-time text generation
3. **Multi-language** - Support multiple languages
4. **Custom Models** - Allow user-selected models
5. **Analytics** - Track usage & performance
6. **Rate Limiting** - Prevent abuse
7. **Caching** - Improve response times
8. **WebSocket** - Real-time bidirectional communication
